This repository is to be released in June 2025.

# PCP-MV

Official project website for the ICRA 2025 paper "[Learning better representations for crowded pedestrians in offboard LiDAR-camera 3D tracking-by-detection](https://arxiv.org/abs/2505.16029)". 

## Environment
Before you start, please refer to [ENV.md](https://github.com/Nicholasli1995/PCP-MV/blob/master/docs/ENV.md) to build this project.

## Data preparation
Please follow [DATASET.md](https://github.com/Nicholasli1995/PCP-MV/blob/master/docs/DATASET.md) to download and prepare the nuScenes dataset.

## Usage: inference demo
Refer to [INFERENCE.md](https://github.com/Nicholasli1995/PCP-MV/blob/master/docs/INFERENCE.md) to perform LiDAR-camera tracking-by-detection and quantitative evaluation.

## Usage: training experiments
Refer to TRAIN.md to perform training with various configurations.

## License
A MIT license is used for this repository. Third-party datasets like nuScenes are subject to their own licenses and the user should obey them strictly.

## Acknowledgement
This repository is developed based on [BEVFusion](https://github.com/mit-han-lab/bevfusion). Thank the authors for their contributions.

## Citation
Please star this repository and cite the following paper in your publications if it helps your research:

    @inproceedings{li2025learning,
      title={Learning better representations for crowded pedestrians in offboard LiDAR-camera 3D tracking-by-detection},
      author={Li, Shichao and Li, Peiliang and Lian, Qing and Yun, Peng and Chen, Xiaozhi},
      booktitle={2023 IEEE international conference on robotics and automation (ICRA)},
      year={2025},
      organization={IEEE}
    }

[Link to the paper](https://arxiv.org/abs/2505.16029)